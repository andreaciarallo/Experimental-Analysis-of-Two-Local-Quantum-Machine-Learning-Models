# qvc TwoLocal incremental log
# combo: rotation_type=RY, entanglement=pairwise, ent_gate=CNOT
# Columns: dim, num_layers, best_it, val_acc, val_loss, val_prec, val_rec, val_f1, lowest train loss, final train loss
2, 1, 120, 0.583333, 0.695618, 0.551020, 0.900000, 0.683544, 0.697583, 0.706588
2, 2, 145, 0.666667, 0.677776, 0.692308, 0.600000, 0.642857, 0.654093, 0.660731
2, 3, 182, 0.650000, 0.732240, 0.909091, 0.333333, 0.487805, 0.687359, 0.698730
2, 4, 89, 0.666667, 0.681564, 0.812500, 0.433333, 0.565217, 0.657217, 0.692593
2, 5, 181, 0.666667, 0.678383, 0.692308, 0.600000, 0.642857, 0.654383, 0.657789
3, 1, 39, 0.550000, 0.679100, 0.488372, 0.807692, 0.608696, 0.714993, 0.715279
3, 2, 166, 0.583333, 0.691476, 0.514286, 0.692308, 0.590164, 0.671863, 0.677172
3, 3, 61, 0.583333, 0.699621, 0.511111, 0.884615, 0.647887, 0.666994, 0.667076
3, 4, 69, 0.666667, 0.676921, 0.666667, 0.461538, 0.545455, 0.656768, 0.664906
3, 5, 162, 0.666667, 0.682002, 0.687500, 0.423077, 0.523810, 0.657243, 0.679320
4, 1, 100, 0.750000, 0.660570, 0.800000, 0.666667, 0.727273, 0.664386, 0.682439
4, 2, 15, 0.783333, 0.653632, 0.814815, 0.733333, 0.771930, 0.622358, 0.628061
4, 3, 10, 0.800000, 0.651133, 0.909091, 0.666667, 0.769231, 0.622331, 0.630902
4, 4, 8, 0.783333, 0.648355, 0.814815, 0.733333, 0.771930, 0.622084, 0.623340
4, 5, 6, 0.716667, 0.649049, 0.782609, 0.600000, 0.679245, 0.622191, 0.636344
5, 1, 90, 0.566667, 0.704667, 0.666667, 0.206897, 0.315789, 0.695762, 0.696167
5, 2, 82, 0.716667, 0.664126, 0.928571, 0.448276, 0.604651, 0.656454, 0.657923
5, 3, 92, 0.566667, 0.712500, 0.560000, 0.482759, 0.518519, 0.653687, 0.676297
5, 4, 143, 0.600000, 0.687742, 0.600000, 0.517241, 0.555556, 0.647837, 0.651047
5, 5, 105, 0.633333, 0.696750, 0.652174, 0.517241, 0.576923, 0.651583, 0.653951
6, 1, 153, 0.633333, 0.685595, 0.846154, 0.354839, 0.500000, 0.672579, 0.691358
6, 2, 182, 0.733333, 0.642720, 0.800000, 0.645161, 0.714286, 0.634677, 0.634917
6, 3, 177, 0.700000, 0.641755, 0.740741, 0.645161, 0.689655, 0.635064, 0.639993
6, 4, 88, 0.716667, 0.631675, 0.666667, 0.903226, 0.767123, 0.633283, 0.633283
6, 5, 158, 0.733333, 0.645306, 0.826087, 0.612903, 0.703704, 0.632946, 0.662325
7, 1, 183, 0.583333, 0.683500, 0.400000, 0.272727, 0.324324, 0.667746, 0.668722
7, 2, 114, 0.716667, 0.654633, 0.692308, 0.409091, 0.514286, 0.635950, 0.635950
7, 3, 130, 0.700000, 0.659779, 0.583333, 0.636364, 0.608696, 0.634082, 0.635594
7, 4, 141, 0.750000, 0.640511, 0.818182, 0.409091, 0.545455, 0.634609, 0.639008
7, 5, 196, 0.700000, 0.686390, 0.600000, 0.545455, 0.571429, 0.637052, 0.640702
8, 1, 58, 0.733333, 0.678923, 0.600000, 0.714286, 0.652174, 0.676478, 0.676670
8, 2, 19, 0.783333, 0.625024, 0.785714, 0.523810, 0.628571, 0.634757, 0.638167
8, 3, 54, 0.766667, 0.624913, 0.733333, 0.523810, 0.611111, 0.633239, 0.633347
8, 4, 8, 0.800000, 0.636491, 0.736842, 0.666667, 0.700000, 0.634900, 0.655143
8, 5, 14, 0.783333, 0.636854, 0.700000, 0.666667, 0.682927, 0.633731, 0.638040
9, 1, 198, 0.600000, 0.699441, 0.558824, 0.678571, 0.612903, 0.702829, 0.703966
9, 2, 108, 0.850000, 0.600478, 0.952381, 0.714286, 0.816327, 0.609494, 0.611174
9, 3, 74, 0.900000, 0.558508, 0.923077, 0.857143, 0.888889, 0.605662, 0.609108
9, 4, 96, 0.900000, 0.570863, 0.923077, 0.857143, 0.888889, 0.605899, 0.607632
9, 5, 99, 0.900000, 0.574688, 0.958333, 0.821429, 0.884615, 0.607994, 0.613784
10, 1, 49, 0.600000, 0.696176, 0.586207, 0.586207, 0.586207, 0.666472, 0.670268
10, 2, 54, 0.750000, 0.647233, 0.750000, 0.724138, 0.736842, 0.615104, 0.619760
10, 3, 46, 0.750000, 0.648884, 0.937500, 0.517241, 0.666667, 0.617415, 0.619222
10, 4, 84, 0.750000, 0.650867, 0.888889, 0.551724, 0.680851, 0.616392, 0.621451
10, 5, 193, 0.750000, 0.644116, 0.937500, 0.517241, 0.666667, 0.617052, 0.622974
