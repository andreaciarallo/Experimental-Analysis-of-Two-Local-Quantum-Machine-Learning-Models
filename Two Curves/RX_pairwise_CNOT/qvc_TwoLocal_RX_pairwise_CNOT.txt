# qvc TwoLocal incremental log
# combo: rotation_type=RX, entanglement=pairwise, ent_gate=CNOT
# Columns: dim, num_layers, best_it, val_acc, val_loss, val_prec, val_rec, val_f1, lowest train loss, final train loss
2, 1, 93, 0.550000, 0.690671, 0.533333, 0.800000, 0.640000, 0.699498, 0.703359
2, 2, 26, 0.616667, 0.684040, 1.000000, 0.233333, 0.378378, 0.663781, 0.663861
2, 3, 44, 0.616667, 0.693180, 1.000000, 0.233333, 0.378378, 0.663928, 0.683948
2, 4, 47, 0.616667, 0.687343, 0.818182, 0.300000, 0.439024, 0.662321, 0.666510
2, 5, 18, 0.600000, 0.682926, 0.714286, 0.333333, 0.454545, 0.662753, 0.664527
3, 1, 58, 0.600000, 0.669632, 0.550000, 0.423077, 0.478261, 0.691137, 0.697277
3, 2, 97, 0.583333, 0.678204, 0.512821, 0.769231, 0.615385, 0.694392, 0.698262
3, 3, 134, 0.616667, 0.693149, 0.545455, 0.692308, 0.610169, 0.692884, 0.707976
3, 4, 118, 0.600000, 0.696731, 0.535714, 0.576923, 0.555556, 0.695773, 0.696025
3, 5, 93, 0.600000, 0.675992, 0.555556, 0.384615, 0.454545, 0.691790, 0.701183
4, 1, 23, 0.616667, 0.695537, 0.818182, 0.300000, 0.439024, 0.697956, 0.703340
4, 2, 161, 0.600000, 0.716772, 1.000000, 0.200000, 0.333333, 0.655442, 0.659246
4, 3, 30, 0.600000, 0.697261, 1.000000, 0.200000, 0.333333, 0.653894, 0.654259
4, 4, 45, 0.566667, 0.706322, 0.750000, 0.200000, 0.315789, 0.652166, 0.653830
4, 5, 21, 0.583333, 0.706176, 1.000000, 0.166667, 0.285714, 0.651907, 0.654557
5, 1, 109, 0.516667, 0.705264, 0.000000, 0.000000, 0.000000, 0.694540, 0.706109
5, 2, 73, 0.666667, 0.690020, 0.764706, 0.448276, 0.565217, 0.660195, 0.665041
5, 3, 67, 0.650000, 0.684144, 0.681818, 0.517241, 0.588235, 0.660168, 0.660901
5, 4, 44, 0.633333, 0.699195, 1.000000, 0.241379, 0.388889, 0.659939, 0.660972
5, 5, 78, 0.650000, 0.684178, 0.681818, 0.517241, 0.588235, 0.659894, 0.660834
6, 1, 177, 0.650000, 0.688163, 0.916667, 0.354839, 0.511628, 0.690708, 0.690708
6, 2, 198, 0.583333, 0.682654, 0.650000, 0.419355, 0.509804, 0.656506, 0.658367
6, 3, 111, 0.633333, 0.679813, 0.680000, 0.548387, 0.607143, 0.656459, 0.665302
6, 4, 75, 0.516667, 0.715235, 0.625000, 0.161290, 0.256410, 0.656508, 0.657638
6, 5, 70, 0.700000, 0.679503, 0.696970, 0.741935, 0.718750, 0.656473, 0.656538
7, 1, 54, 0.700000, 0.682740, 1.000000, 0.181818, 0.307692, 0.683965, 0.689636
7, 2, 155, 0.633333, 0.676959, 0.500000, 0.454545, 0.476190, 0.689439, 0.689792
7, 3, 48, 0.566667, 0.691574, 0.428571, 0.545455, 0.480000, 0.684266, 0.684335
7, 4, 51, 0.666667, 0.669117, 0.666667, 0.181818, 0.285714, 0.683573, 0.684674
7, 5, 20, 0.716667, 0.663877, 1.000000, 0.227273, 0.370370, 0.683699, 0.686515
8, 1, 57, 0.650000, 0.689587, 0.000000, 0.000000, 0.000000, 0.693679, 0.710127
8, 2, 84, 0.716667, 0.644320, 0.625000, 0.476190, 0.540541, 0.653581, 0.653581
8, 3, 24, 0.716667, 0.636407, 0.833333, 0.238095, 0.370370, 0.650426, 0.655579
8, 4, 46, 0.716667, 0.648065, 0.611111, 0.523810, 0.564103, 0.650253, 0.661833
8, 5, 18, 0.716667, 0.651769, 0.611111, 0.523810, 0.564103, 0.643767, 0.644783
9, 1, 37, 0.533333, 0.716842, 0.000000, 0.000000, 0.000000, 0.693143, 0.694890
9, 2, 45, 0.866667, 0.615556, 0.857143, 0.857143, 0.857143, 0.614891, 0.616860
9, 3, 71, 0.866667, 0.569012, 0.954545, 0.750000, 0.840000, 0.614898, 0.616114
9, 4, 69, 0.866667, 0.564767, 0.954545, 0.750000, 0.840000, 0.614892, 0.614952
9, 5, 47, 0.866667, 0.577941, 0.954545, 0.750000, 0.840000, 0.614895, 0.614898
10, 1, 15, 0.583333, 0.703221, 0.541667, 0.896552, 0.675325, 0.666793, 0.667158
10, 2, 171, 0.733333, 0.662582, 0.782609, 0.620690, 0.692308, 0.646429, 0.646430
10, 3, 197, 0.700000, 0.665193, 0.720000, 0.620690, 0.666667, 0.648185, 0.648263
10, 4, 41, 0.700000, 0.656908, 0.866667, 0.448276, 0.590909, 0.644206, 0.646421
10, 5, 41, 0.716667, 0.676657, 0.666667, 0.827586, 0.738462, 0.648856, 0.656810
